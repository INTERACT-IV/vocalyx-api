"""
vocalyx-api/api/endpoints.py
Endpoints de l'API centrale
"""

import uuid
import logging
import asyncio
import json
from datetime import datetime
from pathlib import Path
from typing import List, Optional

from fastapi import (
    APIRouter, Depends, File, HTTPException, Query, 
    UploadFile, Form, status, Request, WebSocket, WebSocketDisconnect
)
from fastapi.security import OAuth2PasswordRequestForm
from datetime import timedelta
from database import User
from api import auth, schemas

from sqlalchemy.orm import Session, joinedload
from sqlalchemy import func, exc, or_

from jose import JWTError, jwt

from database import Transcription, Project, User, SessionLocal
from api.dependencies import (
    get_db, verify_project_key, verify_internal_key, verify_admin_key,
    get_user_from_websocket
)
from api.schemas import (
    TranscriptionResponse, TranscriptionCreate, TranscriptionUpdate,
    ProjectResponse, ProjectCreate, ProjectDetails,
    TranscriptionCountResponse, TaskStatusResponse
)
from celery_app import transcribe_audio_task, get_task_status, cancel_task, get_celery_stats

from fastapi.security import OAuth2PasswordRequestForm
from datetime import timedelta
from api import auth, schemas

logger = logging.getLogger(__name__)
router = APIRouter()
auth_router = APIRouter()
ws_router = APIRouter()

admin_router = APIRouter(
    tags=["Admin Management"],
    dependencies=[Depends(auth.get_current_admin_user)]
)

# ============================================================================
# NOUVELLES FONCTIONS HELPERS (PARTAG√âES)
# ============================================================================

def _load_user_with_projects(db: Session, user_id: str) -> User:
    return (
        db.query(User)
        .options(joinedload(User.projects))
        .filter(User.id == user_id)
        .first()
    )


def _get_allowed_project_names(db: Session, current_user: User) -> Optional[List[str]]:
    if current_user.is_admin:
        return None
    user = _load_user_with_projects(db, current_user.id)
    if not user:
        return []
    return [project.name for project in user.projects]


def _get_db_worker_stats(allowed_projects, db_session):
    """R√©cup√®re uniquement les stats DB par worker"""
    try:
        db_stats_query = db_session.query(
            Transcription.worker_id,
            func.sum(Transcription.duration).label('total_audio_s'),
            func.sum(Transcription.processing_time).label('total_processing_s')
        ).filter(
            Transcription.worker_id != None,
            Transcription.status == 'done'
        )
        if allowed_projects is not None:
            db_stats_query = db_stats_query.filter(Transcription.project_name.in_(allowed_projects))
        db_stats_query = db_stats_query.group_by(
            Transcription.worker_id
        ).all()

        return {
            row.worker_id: {
                'total_audio_processed_s': row.total_audio_s or 0,
                'total_processing_time_s': row.total_processing_s or 0
            }
            for row in db_stats_query
        }
    except Exception as e:
        logger.error(f"Erreur lors de la r√©cup√©ration des stats DB par worker: {e}", exc_info=True)
        return {}

def _get_db_data_sync_internal(filters, allowed_projects, db_session):
        """Fonction interne pour r√©cup√©rer les donn√©es DB"""
        page = filters.get("page", 1)
        limit = filters.get("limit", 25)
        status = filters.get("status")
        project = filters.get("project")
        search = filters.get("search")
        offset = (page - 1) * limit
        
        try:
            logger.info("-> _get_db_data_sync_internal: D√©marrage...")
            filtered_query = db_session.query(Transcription)
            if allowed_projects is not None:
                if not allowed_projects:
                    logger.info("-> _get_db_data_sync_internal: Aucun projet autoris√©, retour √† vide.")
                    return {
                        "transcription_count": {
                            "total_filtered": 0,
                            "pending": 0, "processing": 0, "done": 0, "error": 0, "total_global": 0
                        },
                        "transcriptions": [],
                        "db_worker_stats": {}
                    }
                if project and project not in allowed_projects:
                    logger.info("-> _get_db_data_sync_internal: Projet non autoris√© demand√©.")
                    return {
                        "transcription_count": {
                            "total_filtered": 0,
                            "pending": 0, "processing": 0, "done": 0, "error": 0, "total_global": 0
                        },
                        "transcriptions": [],
                        "db_worker_stats": {}
                    }
                filtered_query = filtered_query.filter(Transcription.project_name.in_(allowed_projects))

            if status:
                filtered_query = filtered_query.filter(Transcription.status == status)
            if project:
                filtered_query = filtered_query.filter(Transcription.project_name == project)
            if search:
                search_term = f"%{search}%"
                filtered_query = filtered_query.filter(
                    or_(
                        Transcription.id.ilike(search_term),
                        Transcription.file_path.ilike(search_term),
                        Transcription.text.ilike(search_term)
                    )
                )
            
            logger.info("-> _get_db_data_sync_internal: Ex√©cution de la requ√™te .count()...")
            total_filtered = filtered_query.count()
            logger.info(f"-> _get_db_data_sync_internal: .count() termin√©. Total: {total_filtered}")

            logger.info("-> _get_db_data_sync_internal: Ex√©cution de la requ√™te group_by(status)...")
            grouped_counts_db = db_session.query(
                Transcription.status,
                func.count(Transcription.id)
            ).group_by(Transcription.status).all()
            logger.info("-> _get_db_data_sync_internal: group_by(status) termin√©.")
            
            count_result = {
                "total_filtered": total_filtered,
                "pending": 0, "processing": 0, "done": 0, "error": 0, "total_global": 0
            }
            for s, count in grouped_counts_db:
                if s in count_result:
                    count_result[s] = count
                    count_result["total_global"] += count

            logger.info("-> _get_db_data_sync_internal: Ex√©cution de la requ√™te principale (limit/offset)...")
            transcriptions_db = filtered_query.order_by(
                Transcription.created_at.desc()
            ).limit(limit).offset(offset).all()
            logger.info("-> _get_db_data_sync_internal: Requ√™te principale termin√©e.")
            
            transcription_list = [t.to_dict() for t in transcriptions_db]

            logger.info("-> _get_db_data_sync_internal: Ex√©cution de la requ√™te stats_db_par_worker...")
            db_stats_query = db_session.query(
                Transcription.worker_id,
                func.sum(Transcription.duration).label('total_audio_s'),
                func.sum(Transcription.processing_time).label('total_processing_s')
            ).filter(
                Transcription.worker_id != None,
                Transcription.status == 'done'
            )
            if allowed_projects is not None:
                db_stats_query = db_stats_query.filter(Transcription.project_name.in_(allowed_projects))
            db_stats_query = db_stats_query.group_by(
                Transcription.worker_id
            ).all()
            logger.info("-> _get_db_data_sync_internal: Requ√™te stats_db_par_worker termin√©e.")

            db_stats_dict = {
                row.worker_id: {
                    'total_audio_processed_s': row.total_audio_s or 0,
                    'total_processing_time_s': row.total_processing_s or 0
                }
                for row in db_stats_query
            }
            
            logger.info("-> _get_db_data_sync_internal: Termin√© avec succ√®s.")
            return {
                "transcription_count": count_result,
                "transcriptions": transcription_list,
                "db_worker_stats": db_stats_dict
            }
        except Exception as e:
            logger.error(f"-> _get_db_data_sync_internal: Erreur DB: {e}", exc_info=True)
            return {"transcription_count": {}, "transcriptions": [], "db_worker_stats": {}}

def _get_db_data_sync_fast(filters, allowed_projects, db_session):
    """Version rapide pour r√©cup√©rer uniquement les donn√©es DB (sans stats Celery)"""
    return _get_db_data_sync_internal(filters, allowed_projects, db_session)

async def get_dashboard_state(filters: dict, allowed_projects: Optional[List[str]] = None) -> dict:
    """
    Fonction helper pour r√©cup√©rer l'√©tat complet du dashboard.
    Ex√©cute les requ√™tes bloquantes (DB, Celery) dans des threads.
    """
    logger.info(f"-> get_dashboard_state: D√©marrage avec filtres: {filters}")
    
    page = filters.get("page", 1)
    limit = filters.get("limit", 25)
    status = filters.get("status")
    project = filters.get("project")
    search = filters.get("search")
    
    offset = (page - 1) * limit
    
    db = SessionLocal() 
    logger.info("-> get_dashboard_state: Session DB cr√©√©e.")

    def get_db_data_sync():
        """Fonction synchrone √† ex√©cuter dans un thread"""
        try:
            return _get_db_data_sync_internal(filters, allowed_projects, db)
        finally:
            logger.info("-> get_db_data_sync: Fermeture de la session DB.")
            db.close() 

    logger.info("-> get_dashboard_state: Lancement de get_celery_stats dans un thread...")
    stats_task = asyncio.to_thread(get_celery_stats)
    
    logger.info("-> get_dashboard_state: Lancement de get_db_data_sync dans un thread...")
    db_task = asyncio.to_thread(get_db_data_sync)

    logger.info("-> get_dashboard_state: Attente de asyncio.gather (Celery + DB)...")
    try:
        worker_stats_result, db_data_result = await asyncio.gather(stats_task, db_task)
        logger.info("-> get_dashboard_state: asyncio.gather termin√©.")
    except Exception as e:
        logger.error(f"-> get_dashboard_state: Erreur lors de asyncio.gather: {e}", exc_info=True)
        if db.is_active:
            db.close()
        raise

    # Fusionner les stats DB dans les stats Celery
    logger.info("-> get_dashboard_state: Fusion des stats DB et Celery...")
    if worker_stats_result.get('stats') and db_data_result.get('db_worker_stats'):
        db_stats_map = db_data_result['db_worker_stats']
        for worker_name, worker_data in worker_stats_result['stats'].items():
            simple_name = worker_name.split('@')[0]
            if simple_name in db_stats_map:
                worker_data['db_stats'] = db_stats_map[simple_name]
            else:
                # S'assurer que 'db_stats' existe toujours
                worker_data['db_stats'] = {
                    'total_audio_processed_s': 0,
                    'total_processing_time_s': 0
                }
    logger.info("-> get_dashboard_state: Fusion termin√©e.")

    # Combiner les r√©sultats
    logger.info("-> get_dashboard_state: Combinaison des r√©sultats...")
    return {
        "worker_stats": worker_stats_result,
        "transcription_count": db_data_result["transcription_count"],
        "transcriptions": db_data_result["transcriptions"]
    }

# ============================================================================
# WEBSOCKET ENDPOINT (MODIFI√â)
# ============================================================================

@ws_router.websocket("/ws/updates")
async def websocket_endpoint(websocket: WebSocket):
    """
    ‚úÖ VERSION FINALE: Endpoint WebSocket sans aucune d√©pendance FastAPI
    Tout est g√©r√© manuellement √† l'int√©rieur de la fonction
    """
    logger.info("=" * 70)
    logger.info("WebSocket: üîå Nouvelle connexion entrante")
    logger.info("=" * 70)
    
    # ‚úÖ √âTAPE 1: ACCEPTER LA CONNEXION IMM√âDIATEMENT
    try:
        await websocket.accept()
        logger.info("WebSocket: ‚úÖ Connexion accept√©e (accept() r√©ussi)")
    except Exception as e:
        logger.error(f"WebSocket: ‚ùå √âchec de accept(): {e}", exc_info=True)
        return
    
    # Cr√©er une session DB manuelle
    db = SessionLocal()
    manager = websocket.app.state.ws_manager
    user = None
    
    try:
        # ‚úÖ √âTAPE 2: R√©cup√©rer le token
        token = websocket.query_params.get("token")
        logger.info(f"WebSocket: Token pr√©sent: {token is not None}")
        
        if token is None:
            logger.warning("WebSocket: ‚ùå Aucun token fourni")
            await websocket.send_json({"type": "error", "message": "Authentication required"})
            await websocket.close(code=status.WS_1008_POLICY_VIOLATION)
            return
        
        logger.debug(f"WebSocket: Token (premiers caract√®res): {token[:30]}...")
        
        # ‚úÖ √âTAPE 3: D√©coder le JWT
        try:
            logger.info("WebSocket: üîê D√©codage du JWT...")
            payload = jwt.decode(token, auth.JWT_SECRET_KEY, algorithms=[auth.JWT_ALGORITHM])
            username: str = payload.get("sub")
            
            if username is None:
                logger.warning("WebSocket: ‚ùå 'sub' manquant dans le JWT")
                await websocket.send_json({"type": "error", "message": "Invalid token format"})
                await websocket.close(code=status.WS_1008_POLICY_VIOLATION)
                return
            
            logger.info(f"WebSocket: ‚úÖ Token d√©cod√© avec succ√®s. Username: '{username}'")
            
        except JWTError as e:
            logger.error(f"WebSocket: ‚ùå Erreur JWT: {e}")
            await websocket.send_json({"type": "error", "message": f"Invalid or expired token: {str(e)}"})
            await websocket.close(code=status.WS_1008_POLICY_VIOLATION)
            return
        
        # ‚úÖ √âTAPE 4: V√©rifier l'utilisateur dans la DB
        logger.info(f"WebSocket: üîç Recherche de l'utilisateur '{username}' dans la DB...")
        user = db.query(User).filter(User.username == username).first()
        
        if user is None:
            logger.warning(f"WebSocket: ‚ùå Utilisateur '{username}' non trouv√© dans la DB")
            await websocket.send_json({"type": "error", "message": "User not found"})
            await websocket.close(code=status.WS_1008_POLICY_VIOLATION)
            return
        
        logger.info(f"WebSocket: ‚úÖ‚úÖ‚úÖ Client '{user.username}' AUTHENTIFI√â AVEC SUCC√àS !")
        allowed_projects = _get_allowed_project_names(db, user)
        
        # ‚úÖ √âTAPE 5: Enregistrer dans le manager
        await manager.connect(websocket)
        logger.info(f"WebSocket: ‚úÖ Client '{user.username}' ajout√© au ConnectionManager")
        
        # ‚úÖ √âTAPE 6: Envoyer l'√©tat initial automatiquement
        # Le client attend maintenant que le WebSocket soit connect√© avant de charger les donn√©es
        # On envoie les donn√©es DB imm√©diatement, puis les stats Celery s√©par√©ment
        try:
            logger.info(f"WebSocket: üìä R√©cup√©ration de l'√©tat initial du dashboard...")
            default_filters = {"page": 1, "limit": 25, "status": None, "project": None, "search": None}
            
            # R√©cup√©rer les donn√©es DB rapidement (sans attendre Celery)
            db = SessionLocal()
            try:
                db_data = await asyncio.to_thread(_get_db_data_sync_fast, default_filters, allowed_projects, db)
                
                # Envoyer les donn√©es DB imm√©diatement
                initial_state_fast = {
                    "transcription_count": db_data["transcription_count"],
                    "transcriptions": db_data["transcriptions"],
                    "worker_stats": None  # Sera mis √† jour plus tard
                }
                
                logger.info(f"WebSocket: üì§ Envoi de l'√©tat initial (DB uniquement) √† '{user.username}'...")
                await websocket.send_json({"type": "initial_dashboard_state", "data": initial_state_fast})
                logger.info(f"WebSocket: ‚úÖ √âtat initial (DB) envoy√© avec succ√®s !")
                
            finally:
                db.close()
            
            # R√©cup√©rer les stats Celery en arri√®re-plan et les envoyer s√©par√©ment
            async def send_celery_stats():
                try:
                    logger.info(f"WebSocket: üìä R√©cup√©ration des stats Celery en arri√®re-plan...")
                    worker_stats_result = await asyncio.to_thread(get_celery_stats)
                    
                    # Fusionner avec les stats DB si n√©cessaire
                    db = SessionLocal()
                    try:
                        db_stats = await asyncio.to_thread(_get_db_worker_stats, allowed_projects, db)
                        if worker_stats_result.get('stats') and db_stats:
                            for worker_name, worker_data in worker_stats_result['stats'].items():
                                simple_name = worker_name.split('@')[0]
                                if simple_name in db_stats:
                                    worker_data['db_stats'] = db_stats[simple_name]
                                else:
                                    worker_data['db_stats'] = {
                                        'total_audio_processed_s': 0,
                                        'total_processing_time_s': 0
                                    }
                    finally:
                        db.close()
                    
                    # Envoyer les stats Celery s√©par√©ment
                    logger.info(f"WebSocket: üì§ Envoi des stats Celery √† '{user.username}'...")
                    await websocket.send_json({"type": "worker_stats", "data": worker_stats_result})
                    logger.info(f"WebSocket: ‚úÖ Stats Celery envoy√©es avec succ√®s !")
                except Exception as e:
                    logger.error(f"WebSocket: ‚ùå Erreur lors de la r√©cup√©ration des stats Celery: {e}", exc_info=True)
            
            # Lancer la r√©cup√©ration des stats Celery en arri√®re-plan (ne pas attendre)
            asyncio.create_task(send_celery_stats())

        except Exception as e:
            logger.error(f"WebSocket: ‚ùå Erreur lors de l'envoi de l'√©tat initial: {e}", exc_info=True)
            await websocket.send_json({"type": "error", "message": "Failed to load initial state"})
        
        # ‚úÖ √âTAPE 7: Boucle keep-alive
        logger.info(f"WebSocket: ‚ôæÔ∏è  Entr√©e dans la boucle keep-alive pour '{user.username}'")
        while True:
            try:
                data = await websocket.receive_json()
                logger.debug(f"WebSocket: Message JSON re√ßu de '{user.username}': {data.get('type')}")
                
                if data.get("type") == "get_dashboard_state":
                    payload = data.get("payload", {})
                    logger.info(f"WebSocket: Demande 'get_dashboard_state' re√ßue avec payload: {payload}")
                    
                    # R√©cup√©rer l'√©tat filtr√©
                    filtered_state = await get_dashboard_state(payload, allowed_projects=allowed_projects)
                    
                    logger.info("WebSocket: √âtat filtr√© r√©cup√©r√©. Envoi au client...")
                    await websocket.send_json({"type": "dashboard_state_update", "data": filtered_state})
                    logger.info("WebSocket: √âtat filtr√© envoy√© au client.")
            except WebSocketDisconnect:
                logger.info(f"WebSocket: üëã Client '{user.username}' d√©connect√© proprement")
                break
            except Exception as e:
                logger.warning(f"WebSocket: ‚ö†Ô∏è Erreur dans la boucle keep-alive: {e}")
                break
        
    except WebSocketDisconnect:
        logger.info("WebSocket: üëã D√©connexion d√©tect√©e (WebSocketDisconnect)")
    except Exception as e:
        logger.error(f"WebSocket: ‚ùå Erreur critique: {e}", exc_info=True)
        try:
            await websocket.send_json({"type": "error", "message": "Internal server error"})
        except:
            logger.warning("WebSocket: Impossible d'envoyer le message d'erreur (connexion ferm√©e)")
    finally:
        # ‚úÖ √âTAPE 8: Nettoyage
        username_log = user.username if user else "Client inconnu"
        logger.info(f"WebSocket: üßπ Nettoyage des ressources pour '{username_log}'...")
        db.close()
        manager.disconnect(websocket)
        logger.info("WebSocket: ‚úÖ Connexion ferm√©e et nettoy√©e")
        logger.info("=" * 70)


# ============================================================================
# AUTHENTIFICATION
# ============================================================================

@auth_router.post("/auth/token", response_model=schemas.Token, tags=["Authentication"])
async def login_for_access_token(
    form_data: OAuth2PasswordRequestForm = Depends(),
    db: Session = Depends(get_db)
):
    """
    Fournit un token JWT en √©change de username/password
    Utilise les services de la clean architecture
    """
    from infrastructure.database.repositories import SQLAlchemyUserRepository
    from infrastructure.security.password_hasher import PasswordHasher
    from infrastructure.security.jwt_service import JWTService
    from application.services.user_service import UserService
    
    # Cr√©er les services
    user_repository = SQLAlchemyUserRepository(db)
    password_hasher = PasswordHasher()
    user_service = UserService(user_repository, password_hasher)
    jwt_service = JWTService(
        secret_key=auth.JWT_SECRET_KEY,
        algorithm=auth.JWT_ALGORITHM,
        expire_minutes=auth.JWT_EXPIRE_MINUTES
    )
    
    # Authentifier l'utilisateur via le service
    user_entity = user_service.authenticate(form_data.username, form_data.password)
    if not user_entity:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Incorrect username or password",
            headers={"WWW-Authenticate": "Bearer"},
        )
    
    # Cr√©er le token
    access_token_expires = timedelta(minutes=auth.JWT_EXPIRE_MINUTES)
    token_data = {
        "sub": user_entity.username,
        "is_admin": user_entity.is_admin
    }
    access_token = jwt_service.create_access_token(
        data=token_data,
        expires_delta=access_token_expires
    )
    
    # Mettre √† jour la derni√®re connexion
    user_service.update_last_login(user_entity)
    
    return {"access_token": access_token, "token_type": "bearer"}

@router.get("/admin/admin-api-key", response_model=ProjectDetails, tags=["Admin"])
def get_admin_api_key(
    request: Request,
    db: Session = Depends(get_db),
    current_user: User = Depends(auth.get_current_user)
):
    """
    [JWT Prot√©g√©] R√©cup√®re les d√©tails (et la cl√©) du projet admin
    """
    config = request.app.state.config
    
    if current_user.username != "admin":
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="Admin access required"
        )
        
    admin_project = db.query(Project).filter(Project.name == config.admin_project_name).first()
    if not admin_project:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Admin project '{config.admin_project_name}' not found"
        )
    
    return admin_project.to_dict_with_key()

# ============================================================================
# GESTION DES UTILISATEURS (NOUVEAU)
# ============================================================================

@admin_router.post("/admin/users", response_model=schemas.UserResponse, status_code=status.HTTP_201_CREATED)
def create_user(
    user_in: schemas.UserCreate, 
    db: Session = Depends(get_db)
):
    """
    [Admin] Cr√©e un nouvel utilisateur (admin ou normal).
    """
    existing_user = db.query(User).filter(User.username == user_in.username).first()
    if existing_user:
        raise HTTPException(
            status_code=status.HTTP_409_CONFLICT,
            detail=f"Username '{user_in.username}' already exists"
        )
    
    hashed_password = auth.get_password_hash(user_in.password)
    
    new_user = User(
        username=user_in.username,
        hashed_password=hashed_password,
        is_admin=user_in.is_admin
    )
    
    db.add(new_user)
    db.commit()
    db.refresh(new_user)
    
    logger.info(f"Admin created new user: {new_user.username} (is_admin={new_user.is_admin})")
    return new_user

@admin_router.get("/admin/users", response_model=List[schemas.UserResponse])
def list_users(db: Session = Depends(get_db)):
    """
    [Admin] Liste tous les utilisateurs et leurs projets associ√©s.
    """
    users = db.query(User).options(
        joinedload(User.projects)
    ).order_by(User.username).all()
    
    return users

@admin_router.post("/admin/users/assign-project", response_model=schemas.UserResponse)
def assign_project_to_user(
    link_in: schemas.UserProjectLink, 
    db: Session = Depends(get_db)
):
    """
    [Admin] Associe un projet √† un utilisateur.
    """
    user = db.query(User).options(joinedload(User.projects)).filter(User.id == link_in.user_id).first()
    if not user:
        raise HTTPException(status_code=404, detail="User not found")
        
    project = db.query(Project).filter(Project.id == link_in.project_id).first()
    if not project:
        raise HTTPException(status_code=404, detail="Project not found")

    if project not in user.projects:
        user.projects.append(project)
        db.commit()
        db.refresh(user)
        logger.info(f"Assigned project '{project.name}' to user '{user.username}'")
    
    return user

@admin_router.post("/admin/users/remove-project", response_model=schemas.UserResponse)
def remove_project_from_user(
    link_in: schemas.UserProjectLink, 
    db: Session = Depends(get_db)
):
    """
    [Admin] Dissocie un projet d'un utilisateur.
    """
    user = db.query(User).options(joinedload(User.projects)).filter(User.id == link_in.user_id).first()
    if not user:
        raise HTTPException(status_code=404, detail="User not found")
        
    project = db.query(Project).filter(Project.id == link_in.project_id).first()
    if not project:
        raise HTTPException(status_code=404, detail="Project not found")

    if project in user.projects:
        user.projects.remove(project)
        db.commit()
        db.refresh(user)
        logger.info(f"Removed project '{project.name}' from user '{user.username}'")
    
    return user

@admin_router.put("/admin/users/{user_id}/password")
def update_user_password(
    user_id: str, 
    password_in: schemas.UserPasswordUpdate, 
    db: Session = Depends(get_db)
):
    """
    [Admin] R√©initialise le mot de passe d'un utilisateur.
    """
    user = db.query(User).filter(User.id == user_id).first()
    if not user:
        raise HTTPException(status_code=404, detail="User not found")
        
    user.hashed_password = auth.get_password_hash(password_in.password)
    db.commit()
    logger.info(f"Admin reset password for user: {user.username}")
    
    return {"status": "password updated", "user_id": user_id}

@admin_router.delete("/admin/users/{user_id}")
def delete_user(user_id: str, db: Session = Depends(get_db)):
    """
    [Admin] Supprime un utilisateur.
    """
    user = db.query(User).filter(User.id == user_id).first()
    if not user:
        raise HTTPException(status_code=404, detail="User not found")
        
    if user.username == "admin":
        raise HTTPException(status_code=403, detail="Cannot delete default admin user")
        
    db.delete(user)
    db.commit()
    logger.info(f"Admin deleted user: {user.username}")
    
    return {"status": "user deleted", "user_id": user_id}

# ============================================================================
# PROJETS
# ============================================================================

@router.post("/projects", response_model=ProjectDetails, status_code=status.HTTP_201_CREATED, tags=["Projects"])
def create_project(
    project: ProjectCreate,
    db: Session = Depends(get_db),
    _: bool = Depends(verify_admin_key)
):
    """Cr√©e un nouveau projet (n√©cessite la cl√© admin)"""
    new_project = Project(name=project.name)
    db.add(new_project)
    
    try:
        db.commit()
        db.refresh(new_project)
        logger.info(f"‚úÖ Project '{new_project.name}' created")
        return new_project.to_dict_with_key()
    except exc.IntegrityError:
        db.rollback()
        raise HTTPException(
            status_code=status.HTTP_409_CONFLICT,
            detail=f"Project '{project.name}' already exists"
        )
    except Exception as e:
        db.rollback()
        logger.error(f"Error creating project: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to create project: {str(e)}"
        )

@router.get("/user/projects", response_model=List[ProjectDetails], tags=["Projects"])
def list_user_projects(
    db: Session = Depends(get_db),
    current_user: User = Depends(auth.get_current_user)
):
    """
    Liste les projets accessibles pour l'utilisateur courant (avec cl√©s API).
    - Admins r√©cup√®rent l'int√©gralit√© des projets.
    - Les utilisateurs standard ne voient que les projets qui leur sont assign√©s.
    """
    if current_user.is_admin:
        projects = db.query(Project).order_by(Project.created_at.desc()).all()
    else:
        user = _load_user_with_projects(db, current_user.id)
        if not user:
            raise HTTPException(status_code=404, detail="User not found")
        projects = list(user.projects)
    
    return [p.to_dict_with_key() for p in projects]


@router.get("/user/me", response_model=schemas.UserResponse, tags=["Users"])
def get_user_profile(
    db: Session = Depends(get_db),
    current_user: User = Depends(auth.get_current_user)
):
    """Retourne le profil de l'utilisateur courant."""
    user = _load_user_with_projects(db, current_user.id)
    if not user:
        raise HTTPException(status_code=404, detail="User not found")
    return user


@router.get("/projects", response_model=List[ProjectResponse], tags=["Projects"])
def list_projects(
    db: Session = Depends(get_db),
    _: bool = Depends(verify_admin_key)
):
    """Liste tous les projets (n√©cessite la cl√© admin)"""
    projects = db.query(Project).order_by(Project.created_at.desc()).all()
    return [p.to_dict() for p in projects]

@router.get("/projects/{project_name}", response_model=ProjectDetails, tags=["Projects"])
def get_project(
    project_name: str,
    db: Session = Depends(get_db),
    _: bool = Depends(verify_admin_key)
):
    """R√©cup√®re les d√©tails d'un projet avec sa cl√© API (n√©cessite la cl√© admin)"""
    project = db.query(Project).filter(Project.name == project_name).first()
    if not project:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"Project '{project_name}' not found"
        )
    return project.to_dict_with_key()

# ============================================================================
# TRANSCRIPTIONS - CR√âATION
# ============================================================================

@router.post("/transcriptions", response_model=TranscriptionResponse, status_code=status.HTTP_201_CREATED, tags=["Transcriptions"])
async def create_transcription(
    request: Request,
    file: UploadFile = File(...),
    project_name: str = Form(...),
    use_vad: bool = Form(True),
    diarization: bool = Form(False),
    whisper_model: str = Form("small"),
    enrichment: bool = Form(False),
    enhanced: bool = Form(False),  # Enrichissement avanc√© avec m√©tadonn√©es (titre, r√©sum√©, etc.)
    llm_model: Optional[str] = Form(None),
    enrichment_prompts: Optional[str] = Form(None),  # JSON stringifi√©
    project: Project = Depends(verify_project_key),
    db: Session = Depends(get_db)
):
    """
    Cr√©e une nouvelle transcription (n√©cessite la cl√© API du projet).
    Upload le fichier et enqueue une t√¢che Celery.
    PUBLIE une mise √† jour sur Redis.
    """
    config = request.app.state.config
    
    # 1. Validation du fichier
    content = await file.read()
    
    max_size_bytes = config.max_file_size_mb * 1024 * 1024
    if len(content) > max_size_bytes:
        raise HTTPException(
            status_code=status.HTTP_413_REQUEST_ENTITY_TOO_LARGE,
            detail=f"File size exceeds {config.max_file_size_mb}MB limit"
        )
    
    filename = file.filename or "upload.bin"
    extension = Path(filename).suffix.lstrip('.').lower()
    if extension not in config.allowed_extensions:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=f"File type '{extension}' not allowed. Allowed: {config.allowed_extensions}"
        )
    
    # 2. Validation du mod√®le Whisper
    valid_models = ["tiny", "base", "small", "medium"]
    if whisper_model not in valid_models:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=f"Invalid whisper_model '{whisper_model}'. Valid models: {', '.join(valid_models)}"
        )
    
    # 3. Sauvegarder le fichier
    transcription_id = str(uuid.uuid4())
    safe_filename = f"{transcription_id}_{filename}"
    file_path = config.upload_dir / safe_filename
    
    try:
        with open(file_path, "wb") as f:
            f.write(content)
    except Exception as e:
        logger.error(f"Failed to save file: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Failed to save uploaded file"
        )
    
    # 4. Parser les prompts d'enrichissement si fournis
    enrichment_prompts_dict = None
    if enrichment_prompts:
        try:
            import json
            enrichment_prompts_dict = json.loads(enrichment_prompts)
        except json.JSONDecodeError:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="Invalid JSON format for enrichment_prompts"
            )
    
    # 5. Cr√©er l'entr√©e en base de donn√©es
    transcription = Transcription(
        id=transcription_id,
        status="pending",
        project_name=project.name,
        file_path=str(file_path),
        whisper_model=whisper_model,
        vad_enabled=1 if use_vad else 0,
        diarization_enabled=1 if diarization else 0,
        enrichment_requested=1 if enrichment else 0,
        enhanced=1 if enhanced else 0,  # Enrichissement avanc√© avec m√©tadonn√©es
        llm_model=llm_model,
        enrichment_status="pending" if enrichment else None,
        enrichment_prompts=json.dumps(enrichment_prompts_dict, ensure_ascii=False) if enrichment_prompts_dict else None,
        created_at=datetime.utcnow()
    )
    db.add(transcription)
    
    try:
        db.commit()
        db.refresh(transcription)
    except Exception as e:
        db.rollback()
        file_path.unlink(missing_ok=True)
        logger.error(f"Database error: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Failed to create database entry"
        )
    
    # 4. Envoyer la t√¢che √† Celery
    try:
        # Envoyer la t√¢che dans la queue 'transcription'
        task = transcribe_audio_task.apply_async(
            args=[transcription_id],
            queue='transcription'
        )
        
        transcription.celery_task_id = task.id
        db.commit()
        
        # --- AJOUT PUBLISH REDIS ---
        redis_pub = request.app.state.redis_pub
        if redis_pub:
            try:
                result = await redis_pub.publish("vocalyx_updates", "new_transcription")
                logger.info(f"üì§ Message Pub/Sub publi√© pour nouvelle transcription (subscribers: {result})")
            except Exception as e:
                logger.error(f"‚ùå Erreur lors de la publication Pub/Sub: {e}", exc_info=True)
        else:
            logger.warning("‚ö†Ô∏è Redis Pub/Sub non disponible, message non publi√©")
        # --- FIN AJOUT ---
            
        logger.info(f"[{transcription_id}] Transcription created for project '{project.name}' | Task: {task.id}")
        
        return transcription.to_dict()
        
    except Exception as e:
        logger.error(f"Failed to enqueue Celery task: {e}")
        transcription.status = "error"
        transcription.error_message = f"Failed to enqueue task: {str(e)}"
        db.commit()
        
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Failed to enqueue transcription task"
        )

# ============================================================================
# TRANSCRIPTIONS - LECTURE
# ============================================================================

@router.get("/transcriptions", response_model=List[TranscriptionResponse], tags=["Transcriptions"])
def list_transcriptions(
    page: int = Query(1, ge=1),
    limit: int = Query(25, ge=1, le=100),
    status: Optional[str] = Query(None),
    project: Optional[str] = Query(None),
    search: Optional[str] = Query(None),
    db: Session = Depends(get_db),
    _: bool = Depends(verify_internal_key)
):
    """
    Liste les transcriptions avec pagination et filtres.
    Endpoint interne (n√©cessite X-Internal-Key)
    """
    query = db.query(Transcription)
    
    if status:
        query = query.filter(Transcription.status == status)
    if project:
        query = query.filter(Transcription.project_name == project)
    if search:
        query = query.filter(Transcription.text.ilike(f"%{search}%"))
    
    offset = (page - 1) * limit
    transcriptions = query.order_by(
        Transcription.created_at.desc()
    ).limit(limit).offset(offset).all()
    
    return [t.to_dict() for t in transcriptions]

@router.get("/transcriptions/count", response_model=TranscriptionCountResponse, tags=["Transcriptions"])
def count_transcriptions(
    status: Optional[str] = Query(None),
    project: Optional[str] = Query(None),
    search: Optional[str] = Query(None),
    db: Session = Depends(get_db),
    _: bool = Depends(verify_internal_key)
):
    """
    Compte les transcriptions avec filtres et retourne les stats globales.
    Endpoint interne (n√©cessite X-Internal-Key)
    """
    filtered_query = db.query(Transcription)
    if status:
        filtered_query = filtered_query.filter(Transcription.status == status)
    if project:
        filtered_query = filtered_query.filter(Transcription.project_name == project)
    if search:
        filtered_query = filtered_query.filter(Transcription.text.ilike(f"%{search}%"))
    
    total_filtered = filtered_query.count()
    
    grouped_counts = db.query(
        Transcription.status,
        func.count(Transcription.id)
    ).group_by(Transcription.status).all()
    
    result = {
        "total_filtered": total_filtered,
        "pending": 0,
        "processing": 0,
        "done": 0,
        "error": 0,
        "total_global": 0
    }
    
    for s, count in grouped_counts:
        if s in result:
            result[s] = count
            result["total_global"] += count
    
    return result

@router.get("/transcriptions/{transcription_id}", response_model=TranscriptionResponse, tags=["Transcriptions"])
def get_transcription(
    transcription_id: str,
    db: Session = Depends(get_db),
    _: bool = Depends(verify_internal_key)
):
    """
    R√©cup√®re une transcription par son ID.
    Endpoint interne (n√©cessite X-Internal-Key)
    """
    transcription = db.query(Transcription).filter(
        Transcription.id == transcription_id
    ).first()
    
    if not transcription:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"Transcription '{transcription_id}' not found"
        )
    
    return transcription.to_dict()


@router.get("/user/transcriptions", response_model=List[TranscriptionResponse], tags=["Transcriptions"])
def list_user_transcriptions(
    page: int = Query(1, ge=1),
    limit: int = Query(25, ge=1, le=100),
    status: Optional[str] = Query(None),
    project: Optional[str] = Query(None),
    search: Optional[str] = Query(None),
    db: Session = Depends(get_db),
    current_user: User = Depends(auth.get_current_user)
):
    """
    Liste les transcriptions auxquelles l'utilisateur courant peut acc√©der.
    """
    query = db.query(Transcription)
    allowed_projects = _get_allowed_project_names(db, current_user)
    if allowed_projects is not None:
        if not allowed_projects:
            return []
        query = query.filter(Transcription.project_name.in_(allowed_projects))
    
    if status:
        query = query.filter(Transcription.status == status)
    if project:
        if allowed_projects is not None and project not in allowed_projects:
            return []
        query = query.filter(Transcription.project_name == project)
    if search:
        query = query.filter(Transcription.text.ilike(f"%{search}%"))
    
    offset = (page - 1) * limit
    transcriptions = query.order_by(
        Transcription.created_at.desc()
    ).limit(limit).offset(offset).all()
    
    return [t.to_dict() for t in transcriptions]


@router.get("/user/transcriptions/count", response_model=TranscriptionCountResponse, tags=["Transcriptions"])
def count_user_transcriptions(
    status: Optional[str] = Query(None),
    project: Optional[str] = Query(None),
    search: Optional[str] = Query(None),
    db: Session = Depends(get_db),
    current_user: User = Depends(auth.get_current_user)
):
    """
    Compte les transcriptions accessibles √† l'utilisateur courant.
    """
    allowed_projects = _get_allowed_project_names(db, current_user)
    if allowed_projects is not None and not allowed_projects:
        return {
            "total_filtered": 0,
            "pending": 0,
            "processing": 0,
            "done": 0,
            "error": 0,
            "total_global": 0
        }
    
    filtered_query = db.query(Transcription)
    if allowed_projects is not None:
        filtered_query = filtered_query.filter(Transcription.project_name.in_(allowed_projects))
    if status:
        filtered_query = filtered_query.filter(Transcription.status == status)
    if project:
        if allowed_projects is not None and project not in allowed_projects:
            return {
                "total_filtered": 0,
                "pending": 0,
                "processing": 0,
                "done": 0,
                "error": 0,
                "total_global": 0
            }
        filtered_query = filtered_query.filter(Transcription.project_name == project)
    if search:
        filtered_query = filtered_query.filter(Transcription.text.ilike(f"%{search}%"))
    
    total_filtered = filtered_query.count()
    
    grouped_counts = filtered_query.with_entities(
        Transcription.status,
        func.count(Transcription.id)
    ).group_by(Transcription.status).all()
    
    result = {
        "total_filtered": total_filtered,
        "pending": 0,
        "processing": 0,
        "done": 0,
        "error": 0,
        "total_global": 0
    }
    
    for s, count in grouped_counts:
        if s in result:
            result[s] = count
            result["total_global"] += count
    
    return result


@router.get("/user/transcriptions/{transcription_id}", response_model=TranscriptionResponse, tags=["Transcriptions"])
def get_user_transcription(
    transcription_id: str,
    db: Session = Depends(get_db),
    current_user: User = Depends(auth.get_current_user)
):
    """
    R√©cup√®re une transcription si l'utilisateur y a acc√®s.
    """
    transcription = db.query(Transcription).filter(
        Transcription.id == transcription_id
    ).first()
    
    if not transcription:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"Transcription '{transcription_id}' not found"
        )
    
    allowed_projects = _get_allowed_project_names(db, current_user)
    if allowed_projects is not None and transcription.project_name not in allowed_projects:
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="Access to this transcription is forbidden"
        )
    
    return transcription.to_dict()

# ============================================================================
# TRANSCRIPTIONS - MISE √Ä JOUR (pour les workers)
# ============================================================================

@router.patch("/transcriptions/{transcription_id}", response_model=TranscriptionResponse, tags=["Transcriptions"])
async def update_transcription(
    transcription_id: str,
    update: TranscriptionUpdate,
    request: Request,
    db: Session = Depends(get_db),
    _: bool = Depends(verify_internal_key)
):
    """
    Met √† jour une transcription (utilis√© par les workers).
    Endpoint interne (n√©cessite X-Internal-Key).
    PUBLIE une mise √† jour sur Redis.
    """
    transcription = db.query(Transcription).filter(
        Transcription.id == transcription_id
    ).first()
    
    if not transcription:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"Transcription '{transcription_id}' not found"
        )
    
    update_data = update.dict(exclude_unset=True)
    
    # G√©rer les champs JSON (enrichment_data)
    if 'enrichment_data' in update_data and update_data['enrichment_data'] is not None:
        if isinstance(update_data['enrichment_data'], str):
            # Si c'est d√©j√† une string JSON, la garder telle quelle
            pass
        else:
            # Si c'est un dict, le convertir en JSON string
            import json
            update_data['enrichment_data'] = json.dumps(update_data['enrichment_data'], ensure_ascii=False)
    
    for key, value in update_data.items():
        if hasattr(transcription, key):
            setattr(transcription, key, value)
    
    if update.status in ["done", "error"] and not transcription.finished_at:
        transcription.finished_at = datetime.utcnow()
    
    try:
        db.commit()
        db.refresh(transcription)
        
        # --- AJOUT PUBLISH REDIS ---
        redis_pub = request.app.state.redis_pub
        if redis_pub:
            try:
                result = await redis_pub.publish("vocalyx_updates", f"update_{transcription_id}")
                logger.info(f"üì§ Message Pub/Sub publi√© pour transcription {transcription_id} (subscribers: {result})")
            except Exception as e:
                logger.error(f"‚ùå Erreur lors de la publication Pub/Sub: {e}", exc_info=True)
        else:
            logger.warning("‚ö†Ô∏è Redis Pub/Sub non disponible, message non publi√©")
        # --- FIN AJOUT ---
            
        logger.info(f"[{transcription_id}] Updated: {update_data}")
        return transcription.to_dict()
    except Exception as e:
        db.rollback()
        logger.error(f"Error updating transcription: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Failed to update transcription"
        )

# ============================================================================
# TRANSCRIPTIONS - SUPPRESSION
# ============================================================================

@router.delete("/transcriptions/{transcription_id}", tags=["Transcriptions"])
async def delete_transcription(
    transcription_id: str,
    request: Request,
    db: Session = Depends(get_db),
    _: bool = Depends(verify_internal_key)
):
    """
    Supprime une transcription et son fichier audio.
    Endpoint interne (n√©cessite X-Internal-Key).
    PUBLIE une mise √† jour sur Redis.
    """
    transcription = db.query(Transcription).filter(
        Transcription.id == transcription_id
    ).first()
    
    if not transcription:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"Transcription '{transcription_id}' not found"
        )
    
    if transcription.file_path:
        try:
            file_path = Path(transcription.file_path)
            if file_path.exists():
                file_path.unlink()
                logger.info(f"[{transcription_id}] File deleted: {file_path.name}")
        except Exception as e:
            logger.warning(f"[{transcription_id}] Failed to delete file: {e}")
    
    db.delete(transcription)
    db.commit()
    
    # --- AJOUT PUBLISH REDIS ---
    redis_pub = request.app.state.redis_pub
    if redis_pub:
        try:
            result = await redis_pub.publish("vocalyx_updates", "delete_transcription")
            logger.info(f"üì§ Message Pub/Sub publi√© pour suppression transcription (subscribers: {result})")
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de la publication Pub/Sub: {e}", exc_info=True)
    else:
        logger.warning("‚ö†Ô∏è Redis Pub/Sub non disponible, message non publi√©")
    # --- FIN AJOUT ---
    
    logger.info(f"[{transcription_id}] Transcription deleted")
    
    return {
        "status": "deleted",
        "id": transcription_id
    }

# ============================================================================
# WORKERS & CELERY
# ============================================================================

@router.get("/workers", tags=["Workers"])
def list_workers(
    db: Session = Depends(get_db),
    _: bool = Depends(verify_internal_key)
):
    """
    Liste les workers Celery actifs et leurs statistiques.
    Endpoint interne (n√©cessite X-Internal-Key).
    Calcule √©galement les stats depuis la DB.
    """
    stats = get_celery_stats() 
    
    try:
        # ‚úÖ REQU√äTE SQL : Calculer les stats par worker depuis la DB
        db_stats_query = db.query(
            Transcription.worker_id,
            func.sum(Transcription.duration).label('total_audio_s'),
            func.sum(Transcription.processing_time).label('total_processing_s'),
            func.count(Transcription.id).label('total_jobs')
        ).filter(
            Transcription.worker_id != None,
            Transcription.status == 'done'
        ).group_by(
            Transcription.worker_id
        ).all()

        # Convertir en dictionnaire
        db_stats_dict = {}
        for row in db_stats_query:
            db_stats_dict[row.worker_id] = {
                'total_audio_processed_s': float(row.total_audio_s or 0),
                'total_processing_time_s': float(row.total_processing_s or 0),
                'total_jobs_completed': int(row.total_jobs or 0)
            }
        
        logger.info(f"üìä Stats DB calcul√©es pour {len(db_stats_dict)} workers: {db_stats_dict}")
        
        # ‚úÖ INJECTION : Injecter les stats DB dans les stats Celery
        if stats.get('stats'):
            for worker_name, worker_data in stats['stats'].items():
                # Extraire le nom simple du worker (ex: "worker-01@host" -> "worker-01")
                simple_name = worker_name.split('@')[0]
                
                if simple_name in db_stats_dict:
                    worker_data['db_stats'] = db_stats_dict[simple_name]
                    logger.debug(f"  ‚úÖ Stats DB inject√©es pour {simple_name}: {db_stats_dict[simple_name]}")
                else:
                    # Worker sans stats DB (nouveau ou aucune t√¢che termin√©e)
                    worker_data['db_stats'] = {
                        'total_audio_processed_s': 0.0,
                        'total_processing_time_s': 0.0,
                        'total_jobs_completed': 0
                    }
                    logger.debug(f"  ‚ÑπÔ∏è Aucune stat DB pour {simple_name}, valeurs par d√©faut")

    except Exception as e:
        logger.error(f"‚ùå Erreur lors du calcul des stats DB: {e}", exc_info=True)
        # En cas d'erreur, mettre des valeurs par d√©faut
        if stats.get('stats'):
            for worker_name, worker_data in stats['stats'].items():
                worker_data['db_stats'] = {
                    'total_audio_processed_s': 0.0,
                    'total_processing_time_s': 0.0,
                    'total_jobs_completed': 0
                }

    logger.info(f"üì§ Envoi des stats workers avec DB stats: {len(stats.get('stats', {}))} workers")
    return stats

# ============================================================================
# T√ÇCHES
# ============================================================================

@router.get("/tasks/{task_id}", response_model=TaskStatusResponse, tags=["Tasks"])
def get_task(
    task_id: str,
    _: bool = Depends(verify_internal_key)
):
    """
    R√©cup√®re le statut d'une t√¢che Celery.
    Endpoint interne (n√©cessite X-Internal-Key)
    """
    return get_task_status(task_id)

@router.post("/tasks/{task_id}/cancel", tags=["Tasks"])
def cancel_task_endpoint(
    task_id: str,
    _: bool = Depends(verify_internal_key)
):
    """
    Annule une t√¢che Celery.
    Endpoint interne (n√©cessite X-Internal-Key)
    """
    return cancel_task(task_id)